# Hadoop
- Hadoop Common
- Hadoop Distributed File System (HDFS)
- Hadoop YARN
- Hadoop MapReduce
- Other modules,  Cassandra, Hive, Pig, Oozie, Flume, and Sqoop

# Spark (compare with Hadoop MapReduce)
- in-disk or in-memory processing vs disk-compute in Hadoop MapReduce
- work with HDFS most of time
- MapReduce uses persistent storage and Spark uses Resilient Distributed Datasets (RDDs)
- in-memory processing make it handle real-time
- Both use HDFS
- memory-costing vs disk-costing

